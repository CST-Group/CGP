{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZaaGPuThxey"
      },
      "source": [
        "# Installing Dependencies and accessing Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3ghKIgLhvkl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55IUU7o2t-0a"
      },
      "outputs": [],
      "source": [
        "!pip install pyctm==0.0.13\n",
        "!pip install pympler\n",
        "!pip install -q memory_profiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6YkLxBwmWuj"
      },
      "outputs": [],
      "source": [
        "%load_ext memory_profiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlVGT2f3uIEv"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1p6J0Dcahant"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as ff\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data_utils\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.data import Dataset\n",
        "from torch.optim import lr_scheduler\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.nn import Parameter\n",
        "import torchvision\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "from torchvision import models\n",
        "import pandas as pd\n",
        "import json as json\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, roc_auc_score, roc_curve, auc\n",
        "\n",
        "from pyctm.representation.sdr_idea_array import SDRIdeaArray\n",
        "from pyctm.representation.sdr_idea_deserializer import SDRIdeaDeserializer\n",
        "from pyctm.representation.sdr_idea_serializer import SDRIdeaSerializer\n",
        "from pyctm.representation.dictionary import Dictionary\n",
        "from pyctm.representation.idea import Idea\n",
        "from pyctm.representation.array_dictionary import ArrayDictionary\n",
        "from pyctm.representation.sdr_idea_array_serializer import SDRIdeaArraySerializer\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AcLRuabiVO7"
      },
      "outputs": [],
      "source": [
        "print(\"\\nChecando GPU...\")\n",
        "\n",
        "print(\"Dispositivo cuda disponível? \", end='')\n",
        "use_gpu = False\n",
        "if torch.cuda.is_available() is True:\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"sim: \" + str(device))\n",
        "    from torch.cuda import get_device_name\n",
        "    use_gpu = True\n",
        "    print(\"GPU:\" + str(get_device_name(0)))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"não. Usando CPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ffex4Bpidcp"
      },
      "source": [
        "## Utils Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4n0rmuVighx"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from torchvision.utils import make_grid\n",
        "import torch\n",
        "\n",
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), nrow=4, show=True):\n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\n",
        "    size per image, plots and prints the images in a uniform grid.\n",
        "    '''\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    # Convert tensor to numpy array\n",
        "    image_array = image_tensor.detach().cpu().numpy()\n",
        "\n",
        "    # Choose a colormap (e.g., 'viridis') to represent the values\n",
        "    cmap = 'viridis'\n",
        "\n",
        "    # Plot each image in the grid\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(nrow, nrow, i + 1)\n",
        "        plt.imshow(image_array[i][0], cmap=cmap, vmin=image_tensor.min(), vmax=image_tensor.max())  # Adiciona vmin e vmax\n",
        "        plt.axis('off')\n",
        "\n",
        "    # Show colorbar\n",
        "    plt.colorbar()\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "\n",
        "# Exemplo de uso:\n",
        "# Suponha que 'tensor_imagens' seja o seu tensor de imagens\n",
        "# show_tensor_images(tensor_imagens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX8BXRFlkRhy"
      },
      "outputs": [],
      "source": [
        "def weights_init(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            nn.init.constant_(m.bias, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nldtjH1luWXL"
      },
      "outputs": [],
      "source": [
        "def get_graph_connection():\n",
        "    graph_connection = {\n",
        "        \"1.0\": [\"2.0\", \"16.0\"],\n",
        "        \"2.0\": [\"1.0\", \"3.0\", \"15.0\"],\n",
        "        \"3.0\": [\"2.0\", \"4.0\", \"14.0\"],\n",
        "        \"4.0\": [\"3.0\", \"5.0\"],\n",
        "        \"5.0\": [\"4.0\", \"6.0\", \"14.0\"],\n",
        "        \"6.0\": [\"5.0\", \"7.0\", \"13.0\"],\n",
        "        \"7.0\": [\"6.0\", \"8.0\"],\n",
        "        \"8.0\": [\"7.0\", \"9.0\", \"12.0\"],\n",
        "        \"9.0\": [\"8.0\", \"10.0\"],\n",
        "        \"10.0\": [\"9.0\", \"11.0\", \"16.0\"],\n",
        "        \"11.0\": [\"10.0\", \"12.0\", \"15.0\"],\n",
        "        \"12.0\": [\"11.0\", \"13.0\", \"8.0\"],\n",
        "        \"13.0\": [\"6.0\", \"12.0\", \"14.0\"],\n",
        "        \"14.0\": [\"3.0\", \"5.0\", \"13.0\", \"15.0\"],\n",
        "        \"15.0\": [\"2.0\", \"11.0\", \"14.0\", \"16.0\"],\n",
        "        \"16.0\": [\"1.0\", \"10.0\", \"15.0\"]\n",
        "    }\n",
        "\n",
        "    return graph_connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3yRVxFquaSu"
      },
      "outputs": [],
      "source": [
        "def is_valid_plan(plan_steps):\n",
        "    for i in range(len(plan_steps) - 1):\n",
        "        current_step = plan_steps[i]\n",
        "        next_step = plan_steps[i + 1]\n",
        "\n",
        "        if current_step.name == \"moveToNode\" and next_step.name == \"moveToNode\":\n",
        "            try:\n",
        "                current_node = str(current_step.value)\n",
        "                next_node = str(next_step.value)\n",
        "                if next_node not in get_graph_connection()[current_node]:\n",
        "                    return False\n",
        "            except Exception as e:\n",
        "                return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def is_valid_plan_v2(action, initial_node, plan_steps, occupiedNodes=[]):\n",
        "    graph_connections = get_graph_connection()  # Armazenar o grafo uma vez\n",
        "\n",
        "    # Criar um conjunto com os nomes dos passos para verificar 'pick' e 'place'\n",
        "    step_names = {step.name for step in plan_steps}\n",
        "\n",
        "    if action == 'PICK':\n",
        "        if 'pick' not in step_names:\n",
        "            return False\n",
        "\n",
        "        current_step = plan_steps[0]\n",
        "        if current_step.name == \"moveToNode\":\n",
        "            if float(current_step.value) != float(initial_node):\n",
        "                current_node = str(current_step.value)\n",
        "                initial_node = str(initial_node)\n",
        "\n",
        "                if current_node not in graph_connections.get(initial_node, []):\n",
        "                    return False\n",
        "\n",
        "    elif action == 'PLACE':\n",
        "        if 'place' not in step_names:\n",
        "            return False\n",
        "\n",
        "    for i in range(len(plan_steps) - 1):\n",
        "        current_step = plan_steps[i]\n",
        "        next_step = plan_steps[i + 1]\n",
        "\n",
        "        if current_step.name == \"moveToNode\" and next_step.name == \"moveToNode\":\n",
        "            current_node = str(current_step.value)\n",
        "            next_node = str(next_step.value)\n",
        "\n",
        "            # Verificar conexão e ocupação do nó em uma única operação\n",
        "            if next_node not in graph_connections.get(current_node, []) or current_node in occupiedNodes:\n",
        "                return False\n",
        "\n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTX3C8FqpXhq"
      },
      "outputs": [],
      "source": [
        "def convert_and_print_idea(new_pattern):\n",
        "    sdr_idea = new_pattern.clone().squeeze(0).detach().cpu().numpy()\n",
        "\n",
        "    action_step_idea = sdr_idea_deserializer.deserialize(sdr_idea)\n",
        "\n",
        "    if action_step_idea is not None:\n",
        "        if action_step_idea.id is None:\n",
        "            action_step_idea.id = 'Undefined'\n",
        "\n",
        "        if action_step_idea.name is None:\n",
        "            action_step_idea.name = 'Undefined'\n",
        "\n",
        "        if action_step_idea.type is None:\n",
        "            action_step_idea.type = 'Undefined'\n",
        "\n",
        "        if action_step_idea.value is None:\n",
        "            action_step_idea.value = 'Undefined'\n",
        "\n",
        "        print(f'Id:{action_step_idea.id}, Name: {action_step_idea.name}, Type: {action_step_idea.type}, Value: {action_step_idea.value}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjqBbbwRpaLt"
      },
      "outputs": [],
      "source": [
        "def is_valid_idea(stepIdea):\n",
        "    if stepIdea.name == \"pick\" or stepIdea.name == \"place\":\n",
        "        if (isinstance(stepIdea.value, list) and\n",
        "            len(stepIdea.value) == 2 and\n",
        "            0 <= stepIdea.value[0] <= 187 and\n",
        "            1 <= stepIdea.value[1] <= 4):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    elif stepIdea.name == \"moveTo\":\n",
        "        if isinstance(stepIdea.value, float) and 0 <= stepIdea.value <= 187:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    elif stepIdea.name == \"moveToNode\":\n",
        "        if isinstance(stepIdea.value, float) and 1 <= stepIdea.value <= 16:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "\n",
        "    return True\n",
        "\n",
        "def treat_idea(action_step_idea):\n",
        "\n",
        "  if action_step_idea is not None:\n",
        "        if action_step_idea.id is None:\n",
        "            action_step_idea.id = 'Undefined'\n",
        "\n",
        "        if action_step_idea.name is None:\n",
        "            action_step_idea.name = 'Undefined'\n",
        "\n",
        "        if action_step_idea.type is None:\n",
        "            action_step_idea.type = 'Undefined'\n",
        "\n",
        "        if action_step_idea.value is None:\n",
        "            action_step_idea.value = 'Undefined'\n",
        "\n",
        "\n",
        "  return action_step_idea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vnUwIcFpgN4"
      },
      "outputs": [],
      "source": [
        "def json_to_idea(data):\n",
        "    idea = Idea(data[\"id\"], data[\"name\"], data[\"value\"], data[\"type\"])\n",
        "    if \"l\" in data:\n",
        "        for child_data in data[\"l\"]:\n",
        "            child_idea = json_to_idea(child_data)\n",
        "            idea.add(child_idea)\n",
        "    return idea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEjpFkX_btB6"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MlyGP-aOYpk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from torch.nn import TransformerEncoderLayer, TransformerDecoderLayer\n",
        "import copy\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_length):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class TransformerXLAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_head, dropout=0.1):\n",
        "        super(TransformerXLAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_head = n_head\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Initialize query, key, and value linear transformations\n",
        "        self.W_Q = nn.Linear(d_model, d_model)\n",
        "        self.W_K = nn.Linear(d_model, d_model)\n",
        "        self.W_V = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # Initialize output linear transformation\n",
        "        self.W_O = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        # Linear transformations\n",
        "        Q = self.W_Q(Q)\n",
        "        K = self.W_K(K)\n",
        "        V = self.W_V(V)\n",
        "\n",
        "        # Split heads\n",
        "        Q = self.split_heads(Q, self.n_head)\n",
        "        K = self.split_heads(K, self.n_head)\n",
        "        V = self.split_heads(V, self.n_head)\n",
        "\n",
        "        # Scale dot product attention\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_model)\n",
        "\n",
        "        # Apply mask if provided\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attn_probs = F.softmax(attn_scores, dim=-1)\n",
        "        attn_probs = self.dropout(attn_probs)\n",
        "\n",
        "        # Weighted sum of values\n",
        "        attn_output = torch.matmul(attn_probs, V)\n",
        "\n",
        "        # Combine heads\n",
        "        attn_output = self.combine_heads(attn_output)\n",
        "\n",
        "        # Linear transformation for output\n",
        "        attn_output = self.W_O(attn_output)\n",
        "\n",
        "        return attn_output\n",
        "\n",
        "    def split_heads(self, x, n_head):\n",
        "        batch_size, seq_len, d_model = x.size()\n",
        "        head_dim = d_model // n_head\n",
        "        x = x.view(batch_size, seq_len, n_head, head_dim)\n",
        "        return x.transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, n_head, seq_len, head_dim = x.size()\n",
        "        x = x.transpose(1, 2).contiguous()\n",
        "        return x.view(batch_size, seq_len, n_head * head_dim)\n",
        "\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))\n",
        "\n",
        "class ResidualLayer(nn.Module):\n",
        "    def __init__(self, sublayer, input_dim):\n",
        "        super(ResidualLayer, self).__init__()\n",
        "        self.sublayer = sublayer\n",
        "        self.norm = nn.LayerNorm(input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.sublayer(self.norm(x))\n",
        "\n",
        "class ConvolutionalEmbeddingLayer1D(nn.Module):\n",
        "    def __init__(self, input_dim, d_model):\n",
        "        super(ConvolutionalEmbeddingLayer1D, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_dim, d_model, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x.permute(0, 2, 1)))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        return x.permute(0, 2, 1)\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = TransformerXLAttention(d_model, n_head, dropout)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = TransformerXLAttention(d_model, n_head, dropout)\n",
        "        self.cross_attn = TransformerXLAttention(d_model, n_head, dropout)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "\n",
        "class PlanningTransformer(nn.Module):\n",
        "    def __init__(self, vocabulary_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, max_seq_len=20, device='cpu'):\n",
        "        super(PlanningTransformer, self).__init__()\n",
        "\n",
        "        self.vocabulary_size = vocabulary_size\n",
        "        self.d_model = d_model\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.device = device\n",
        "\n",
        "        self.encoder_embedding = nn.Embedding(vocabulary_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(vocabulary_size, d_model)\n",
        "\n",
        "        # Positional Encoding\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_len)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, nhead, dim_feedforward, dropout) for _ in range(num_encoder_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, nhead, dim_feedforward, dropout) for _ in range(num_decoder_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.output_layer =nn.Linear(d_model, self.vocabulary_size)\n",
        "\n",
        "    def generate_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).to(self.device).unsqueeze(1).unsqueeze(2)\n",
        "        tgt_mask = (tgt != 0).to(self.device).unsqueeze(1).unsqueeze(3)\n",
        "        seq_length = tgt.size(1)\n",
        "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(self.device)\n",
        "        tgt_mask = tgt_mask & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "\n",
        "    def create_positional_encoding(self, max_len, d_model):\n",
        "        # Create a matrix of positional encodings\n",
        "        positional_encoding = torch.zeros(max_len, d_model).to(self.device)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(position * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(position * div_term)\n",
        "        positional_encoding = positional_encoding.unsqueeze(0)\n",
        "        return nn.Parameter(positional_encoding, requires_grad=False)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        batch_size_tgt, seq_len_tgt = tgt.size()\n",
        "        batch_size, seq_len = src.size()\n",
        "\n",
        "        src = src.to(self.device)\n",
        "        tgt = tgt.to(self.device)\n",
        "\n",
        "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        output = self.output_layer(dec_output)\n",
        "\n",
        "        output = output.view(batch_size_tgt, seq_len_tgt, self.vocabulary_size)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3G6rLlYgt_a"
      },
      "source": [
        "# Data Treatments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtV9eTx0hhST"
      },
      "source": [
        "## Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjChcpc8gw2V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class PlanDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input = torch.from_numpy(np.asarray(self.dataset[\"input\"].values[index]))\n",
        "        label = torch.from_numpy(np.asarray(self.dataset[\"output\"].values[index]))\n",
        "\n",
        "        input = input.long()\n",
        "        label = label.long()\n",
        "\n",
        "        return input, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM6r0BDUhkn1"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lG4lYN75kbzB"
      },
      "outputs": [],
      "source": [
        "!gdown --id 13kkDkMDlTOfFU4kNQrEenvMPcDYC64hr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPXiHGyiiCrm"
      },
      "outputs": [],
      "source": [
        "!rm -rf dataPlanSDR/\n",
        "!unzip \"/content/drive/MyDrive/data/SDR/dataPlanSDR35.zip\" -d ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77rIV8Kohpu-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json(\"/content/dataPlanSDR/dataPlanSDR_0.json\")\n",
        "\n",
        "for i in range(1,2499):\n",
        "  df = pd.concat([df, pd.read_json(\"/content/dataPlanSDR/dataPlanSDR_%s.json\" % i)])\n",
        "  print(\"Loaded File - dataPlanSDR_%s.json\" % i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esSCAsrdiq3-"
      },
      "source": [
        "### Spliting Data - Train and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5yFAJZdiuNF"
      },
      "outputs": [],
      "source": [
        "train_df, validation_df, test_df = \\\n",
        "              np.split(df.sample(frac=1, random_state=42),\n",
        "                       [int(.9*len(df)), int(.95*len(df))])\n",
        "\n",
        "train_size = len(train_df)\n",
        "\n",
        "print(\"Train Size:\" + str(len(train_df)))\n",
        "print(\"Validation Size:\" + str(len(validation_df)))\n",
        "print(\"Test Size:\" + str(len(test_df)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9VPLWRGr7lG"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTPKK0HCpzDL"
      },
      "source": [
        "## Instanciate data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwRfXs6np4pq"
      },
      "outputs": [],
      "source": [
        "train_plan_dataset = PlanDataset(train_df)\n",
        "train_data_loader = DataLoader(train_plan_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "validation_plan_dataset = PlanDataset(validation_df)\n",
        "validation_data_loader = DataLoader(validation_plan_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_plan_dataset = PlanDataset(test_df)\n",
        "test_data_loader = DataLoader(test_plan_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLLe4RFmggTh"
      },
      "source": [
        "## Instanciate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f32XEFz-ffUF"
      },
      "outputs": [],
      "source": [
        "gen = PlanningTransformer(vocabulary_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, max_seq_len, device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CHjmHQcy6no"
      },
      "outputs": [],
      "source": [
        "gen.load_state_dict(torch.load(\"/content/drive/MyDrive/data/models/generators/generator_P_SM_12_768_TRANS_E100_231024.pth\", map_location=torch.device('cpu')))\n",
        "gen = gen.to(device)\n",
        "\n",
        "gen.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZqORS06aJrj"
      },
      "source": [
        "## Deserializer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P46d0ZHhaMFF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from pyctm.representation.array_value_validation import ArrayValueValidation\n",
        "from pyctm.representation.idea import Idea\n",
        "from pyctm.representation.idea_metadata_values import IdeaMetadataValues\n",
        "from pyctm.representation.array_value_converter import ArrayValueConverter\n",
        "from pyctm.representation.value_validation import ValueValidation\n",
        "\n",
        "class SDRIdeaArrayDeserializer:\n",
        "    def __init__(self, dictionary, device='cpu'):\n",
        "        self.dictionary = dictionary\n",
        "        if self.dictionary is not None:\n",
        "            # Assuming dictionary words are already tensors on the correct device\n",
        "            self.dictionary.words = {\n",
        "                int(key): value for key, value in self.dictionary.words.items()\n",
        "            }\n",
        "        self.value_converter = ArrayValueConverter()\n",
        "        self.start_word = 1\n",
        "        self.end_word = 2\n",
        "        self.device = device\n",
        "\n",
        "        # Cache IdeaMetadataValues and metadata map\n",
        "        self.idea_metadata_values = IdeaMetadataValues()\n",
        "        self.metadata_map = self.idea_metadata_values.get_metadata_map()\n",
        "\n",
        "    def deserialize(self, sdr_idea_array):\n",
        "        if sdr_idea_array is None or sdr_idea_array.sdr is None:\n",
        "            raise Exception(\"SDR Idea Array is null or empty.\")\n",
        "\n",
        "        idea_relationship = {}\n",
        "        idea_list = []\n",
        "\n",
        "        sdr = sdr_idea_array.sdr\n",
        "        index = 0\n",
        "        # Convert SDR to tensor and move to device\n",
        "        sdr_tensor = sdr.clone().detach().to(self.device)\n",
        "        # Create a mapping from SDR indices to dictionary words\n",
        "        sdr_words = [self.dictionary.words[str(token.item())] for token in sdr_tensor]\n",
        "\n",
        "        while index < len(sdr_tensor):\n",
        "            token = sdr_tensor[index].item()\n",
        "            if token == self.start_word:\n",
        "                index += 1\n",
        "                continue\n",
        "            elif token == self.end_word:\n",
        "                break\n",
        "\n",
        "            idea = Idea()\n",
        "\n",
        "            parent_id = None\n",
        "            if idea_list:\n",
        "                value, index = self.get_numeric_value(sdr_tensor, index)\n",
        "                parent_id = self.get_value_according_type(value, \"long\")\n",
        "\n",
        "            value, index = self.get_numeric_value(sdr_tensor, index)\n",
        "            idea.id = self.get_value_according_type(value, \"long\")\n",
        "            idea.name, index = self.get_string_value(sdr_tensor, index)\n",
        "\n",
        "            idea_type_str, index = self.get_string_value(sdr_tensor, index)\n",
        "            idea.type = int(idea_type_str)\n",
        "            idea.value, index = self.get_value(sdr_tensor, index)\n",
        "\n",
        "            if parent_id is not None:\n",
        "                idea_relationship[idea.id] = parent_id\n",
        "\n",
        "            idea_list.append(idea)\n",
        "\n",
        "        # Create a mapping from idea IDs to ideas for quick lookup\n",
        "        idea_id_map = {idea.id: idea for idea in idea_list}\n",
        "\n",
        "        for idea_element in idea_list:\n",
        "            # Get IDs of child ideas whose parent is the current idea\n",
        "            child_ids = [\n",
        "                child_id for child_id, parent_id in idea_relationship.items()\n",
        "                if parent_id == idea_element.id\n",
        "            ]\n",
        "            # Add child ideas to the current idea's child_ideas list\n",
        "            for child_id in child_ids:\n",
        "                child_idea = idea_id_map.get(child_id)\n",
        "                if child_idea:\n",
        "                    idea_element.child_ideas.append(child_idea)\n",
        "\n",
        "        return idea_list[0] if idea_list else None\n",
        "\n",
        "    def get_numeric_value(self, sdr_tensor, index):\n",
        "        digits = []\n",
        "        for i in range(3):\n",
        "            token = sdr_tensor[index + i].item()\n",
        "            digit = int(self.dictionary.words[str(token)])\n",
        "            digits.append(digit)\n",
        "        index += 3\n",
        "\n",
        "        value = digits[0] + digits[1] * 0.1 + digits[2] * 0.01\n",
        "\n",
        "        signal_token = sdr_tensor[index].item()\n",
        "        signal = self.dictionary.words[str(signal_token)]\n",
        "        index += 1\n",
        "        base_token = sdr_tensor[index].item()\n",
        "        base = int(self.dictionary.words[str(base_token)])\n",
        "        index += 1\n",
        "        base_signal_token = sdr_tensor[index].item()\n",
        "        base_signal = self.dictionary.words[str(base_signal_token)]\n",
        "        index += 1\n",
        "\n",
        "        exponent = base * (1 if base_signal == \"+\" else -1)\n",
        "        value *= 10 ** exponent\n",
        "        value = value if signal == \"+\" else -value\n",
        "        value = round(value, 2)\n",
        "\n",
        "        return value, index\n",
        "\n",
        "    def get_local_string_value(self, index):\n",
        "        value = self.dictionary.words[str(index)]\n",
        "        return value\n",
        "\n",
        "    def get_string_value(self, sdr_tensor, index):\n",
        "        token = sdr_tensor[index].item()\n",
        "        value = self.dictionary.words[str(token)]\n",
        "        index += 1\n",
        "        return value, index\n",
        "\n",
        "    def get_value(self, sdr_tensor, index):\n",
        "        metadata_token = sdr_tensor[index].item()\n",
        "        metadata_value = int(self.dictionary.words[str(metadata_token)])\n",
        "        index += 1\n",
        "\n",
        "        length_value, index = self.get_numeric_value(sdr_tensor, index)\n",
        "        length = self.get_value_according_type(length_value, \"int\")\n",
        "\n",
        "        for clazz, metadata in self.metadata_map.items():\n",
        "            if metadata == metadata_value:\n",
        "                if ArrayValueValidation.is_array(clazz):\n",
        "                    array_value, index = self.get_array_value(sdr_tensor, index, length, clazz)\n",
        "                    return array_value, index\n",
        "                elif ArrayValueValidation.is_primitive(clazz):\n",
        "                    value, index = self.get_numeric_value(sdr_tensor, index)\n",
        "                    return self.get_value_according_type(value, clazz), index\n",
        "                elif ArrayValueValidation.is_string(clazz):\n",
        "                    value, index = self.get_string_value(sdr_tensor, index)\n",
        "                    return value, index\n",
        "        return None, index\n",
        "\n",
        "    def get_array_value(self, sdr_tensor, index, length, clazz):\n",
        "        array = []\n",
        "        for _ in range(length):\n",
        "            if clazz in [\"list_double\", \"list_float\"]:\n",
        "                value, index = self.get_numeric_value(sdr_tensor, index)\n",
        "                array.append(self.get_value_according_type(value, \"float\"))\n",
        "            elif clazz == \"list_int\":\n",
        "                value, index = self.get_numeric_value(sdr_tensor, index)\n",
        "                array.append(self.get_value_according_type(value, \"int\"))\n",
        "            elif clazz == \"list_short\":\n",
        "                value, index = self.get_numeric_value(sdr_tensor, index)\n",
        "                array.append(self.get_value_according_type(value, \"short\"))\n",
        "            elif clazz == \"list_bool\":\n",
        "                value, index = self.get_string_value(sdr_tensor, index)\n",
        "                array.append(value == \"True\")\n",
        "            elif clazz == \"list_long\":\n",
        "                value, index = self.get_numeric_value(sdr_tensor, index)\n",
        "                array.append(self.get_value_according_type(value, \"long\"))\n",
        "            elif clazz == \"list_str\":\n",
        "                value, index = self.get_string_value(sdr_tensor, index)\n",
        "                array.append(value)\n",
        "        return array, index\n",
        "\n",
        "    def get_value_according_type(self, value, clazz):\n",
        "        if clazz == \"int\":\n",
        "            return int(value)\n",
        "        elif clazz == \"float\":\n",
        "            return float(value)\n",
        "        elif clazz == \"short\":\n",
        "            return int(value)  # Python does not have a native 'short' type\n",
        "        elif clazz == \"long\":\n",
        "            return int(value)\n",
        "        elif clazz == \"double\":\n",
        "            return float(value)\n",
        "        else:\n",
        "            return value\n",
        "\n",
        "    def get_metadata_type(self, metadata_value):\n",
        "        idea_metadata_values = IdeaMetadataValues()\n",
        "        metadata_map = idea_metadata_values.get_metadata_map()\n",
        "        for clazz, metadata in metadata_map.items():\n",
        "            if metadata == metadata_value:\n",
        "                if ArrayValueValidation.is_array(clazz):\n",
        "                    if \"list_str\" == clazz:\n",
        "                        return \"STRING_ARRAY\"\n",
        "                    else:\n",
        "                        return \"NUM_ARRAY\"\n",
        "                elif ArrayValueValidation.is_primitive(clazz):\n",
        "                    return \"NUM_VALUE\"\n",
        "                elif ArrayValueValidation.is_string(clazz):\n",
        "                    return \"STRING_VALUE\"\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWkEMHx90xNJ"
      },
      "outputs": [],
      "source": [
        "file = open(\"/content/dataPlanSDR/dictionary.json\")\n",
        "\n",
        "object=json.load(file)\n",
        "\n",
        "print(object)\n",
        "\n",
        "dictionary = ArrayDictionary(**object)\n",
        "\n",
        "sdr_idea_serializer = SDRIdeaArraySerializer(total_of_ideas=6, total_of_values=7, default_value=0, dictionary=dictionary)\n",
        "sdr_idea_deserializer = SDRIdeaArrayDeserializer(sdr_idea_serializer.dictionary, device=device)\n",
        "\n",
        "sdr_idea_deserializer.dictionary.words = {str(key): value for key, value in sdr_idea_deserializer.dictionary.words.items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_HpV5dMR6n0"
      },
      "source": [
        "## Situated Beam Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFwHpRA5bHbg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class SDRIdeaArrayPredictor:\n",
        "\n",
        "    def __init__(self, sdr_idea_deserializer):\n",
        "        self.sdr_idea_deserializer = sdr_idea_deserializer\n",
        "        self.sdr_idea_deserializer.dictionary.words = {str(key): value for key, value in sdr_idea_deserializer.dictionary.words.items()}\n",
        "        self.step_index = {\n",
        "            \"NUMBER\": [6,7,8,9,10,11,12,13,14,15],\n",
        "            \"SIGNAL\": [4,5],\n",
        "            \"STRING\": [16,19,20,22,23,24,25,27,28,29,30,31,32],\n",
        "            \"TYPE\": [17],\n",
        "            \"METADATA\": [17, 18, 21, 26],\n",
        "            \"SPECIAL\": [2],\n",
        "            \"END\": [2,6,7,8,9,10,11,12,13,14,15]\n",
        "        }\n",
        "        self.steps_dict = {\n",
        "            \"PARENT_ID\": [\"END\", \"NUMBER\", \"NUMBER\", \"SIGNAL\", \"NUMBER\", \"SIGNAL\"],\n",
        "            \"ID\": [\"NUMBER\", \"NUMBER\", \"NUMBER\", \"SIGNAL\", \"NUMBER\", \"SIGNAL\"],\n",
        "            \"NAME\": [\"STRING\"],\n",
        "            \"TYPE\": [\"TYPE\"],\n",
        "            \"METADATA\": [\"METADATA\"],\n",
        "            \"LENGTH\": [\"NUMBER\", \"NUMBER\", \"NUMBER\", \"SIGNAL\", \"NUMBER\", \"SIGNAL\"],\n",
        "            \"NUM_VALUE\": [\"NUMBER\", \"NUMBER\", \"NUMBER\", \"SIGNAL\", \"NUMBER\", \"SIGNAL\"],\n",
        "            \"STRING_VALUE\": [\"STRING\"],\n",
        "            \"END\": [\"END\"]\n",
        "        }\n",
        "        self.parent_states = [\"PARENT_ID\", \"ID\", \"NAME\", \"TYPE\", \"METADATA\", \"LENGTH\"]\n",
        "        self.states = [\"ID\", \"NAME\", \"TYPE\", \"METADATA\", \"LENGTH\"]\n",
        "        self.end_symbol = 2  # Will be set in beam_search\n",
        "\n",
        "    def sample_gumbel(self, shape, device, eps=1e-20):\n",
        "        \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
        "        U = torch.rand(shape, device=device)\n",
        "        return -torch.log(-torch.log(U + eps) + eps)\n",
        "\n",
        "    def gumbel_softmax(self, logits, temperature, scale):\n",
        "        \"\"\"Applies Gumbel-Softmax sampling to the logits.\"\"\"\n",
        "        gumbel_noise = self.sample_gumbel(logits.size(), logits.device)\n",
        "        y = logits + gumbel_noise * 5 * math.tanh(scale)\n",
        "        return F.softmax(y / temperature, dim=-1)\n",
        "\n",
        "    def beam_search(self, model, src, start_symbol, end_symbol, max_len, beam_size, temperature, sdr_idea_deserializer, device):\n",
        "\n",
        "        self.end_symbol = end_symbol  # Set the end symbol for use in get_allowed_tokens\n",
        "        src = src.to(device)\n",
        "        ys = torch.LongTensor([[start_symbol]]).type_as(src.data).to(device)\n",
        "        initial_states = self.get_states(False)\n",
        "        current_state = initial_states.pop(0)\n",
        "        steps = self.get_steps(current_state)\n",
        "        beam = [(ys, 0.0, current_state, initial_states, steps)]\n",
        "        finished_beams = []\n",
        "\n",
        "        model.to(device).eval()\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            beam_candidates = []\n",
        "            batch_size = len(beam)\n",
        "            batch_src = src.repeat(batch_size, 1).to(device)\n",
        "            batch_answers = []\n",
        "            batch_current_states = []\n",
        "            batch_states = []\n",
        "            batch_steps = []\n",
        "            original_beam_indices = []\n",
        "\n",
        "            # Prepare batch inputs\n",
        "            for idx, beam_item in enumerate(beam):\n",
        "                answer, score, current_state, states, steps = beam_item\n",
        "                if answer[0, -1].item() == end_symbol:\n",
        "                    finished_beams.append(beam_item)\n",
        "\n",
        "                    finished_beams.sort(key=lambda x: x[1])\n",
        "                    if len(finished_beams) > beam_size:\n",
        "                        finished_beams = finished_beams[:beam_size]\n",
        "\n",
        "                    continue\n",
        "\n",
        "                batch_answers.append(answer)\n",
        "                batch_current_states.append(current_state)\n",
        "                batch_states.append(states)\n",
        "                batch_steps.append(steps)\n",
        "                original_beam_indices.append(idx)\n",
        "\n",
        "            if not batch_answers:\n",
        "                break  # All beams are finished\n",
        "\n",
        "            batch_answers_tensor = torch.cat(batch_answers, dim=0).to(device)\n",
        "            batch_src = batch_src[:batch_answers_tensor.shape[0], :]\n",
        "\n",
        "            # Forward pass through the model\n",
        "            with torch.no_grad():\n",
        "                logits = model(batch_src, batch_answers_tensor)[:, -1, :]  # Get logits for all items\n",
        "\n",
        "            for idx in range(len(batch_answers)):\n",
        "                answer = batch_answers[idx]\n",
        "                score = beam[original_beam_indices[idx]][1]\n",
        "                current_state = batch_current_states[idx]\n",
        "                states = batch_states[idx]\n",
        "                steps = batch_steps[idx]\n",
        "\n",
        "                current_state, current_step, states_copy, steps_copy, allowed_tokens = self.get_allowed_tokens(\n",
        "                    current_state, states.copy(), steps.copy()\n",
        "                )\n",
        "\n",
        "                allowed_tokens_tensor = torch.tensor(allowed_tokens, dtype=torch.long).to(device)\n",
        "\n",
        "                # Get logits for allowed tokens only\n",
        "                allowed_logits = logits[idx, allowed_tokens_tensor]\n",
        "\n",
        "                scale = temperature\n",
        "\n",
        "                # Apply Gumbel-Softmax to allowed_logits on GPU\n",
        "                if current_state in ['ID', 'PARENT_ID', 'TYPE', 'METADATA', 'LENGTH', 'END']  or current_step in ['SIGNAL'] or temperature == 0:\n",
        "                  allowed_probs = self.gumbel_softmax(allowed_logits, 1e-10, 0)\n",
        "                else:\n",
        "                  allowed_probs = self.gumbel_softmax(allowed_logits, temperature, scale)\n",
        "\n",
        "                # Select top candidates\n",
        "                top_limit = min(beam_size, len(allowed_tokens))\n",
        "                top_probs, indices_in_allowed = allowed_probs.topk(top_limit)\n",
        "\n",
        "                top_ix = allowed_tokens_tensor[indices_in_allowed]\n",
        "\n",
        "                for i in range(top_limit):\n",
        "                    prob = top_probs[i].item()\n",
        "                    ix = top_ix[i].item()\n",
        "                    next_answer = torch.cat([answer, torch.tensor([[ix]], device=device)], dim=1)\n",
        "                    next_score = score - math.log(prob + 1e-8)  # Add epsilon to avoid log(0)\n",
        "\n",
        "                    new_steps = steps_copy.copy()\n",
        "                    new_states = states_copy.copy()\n",
        "                    new_current_state = current_state\n",
        "\n",
        "                    new_current_state = self.validate_and_extend_steps(new_current_state, new_states, new_steps, next_answer)\n",
        "\n",
        "                    beam_candidates.append((next_answer, next_score, new_current_state, new_states, new_steps))\n",
        "\n",
        "            if not beam_candidates:\n",
        "                break\n",
        "\n",
        "            # Sort and select top beams\n",
        "            beam_candidates.sort(key=lambda x: x[1])  # Sort in ascending order of score\n",
        "            beam = beam_candidates[:beam_size]\n",
        "\n",
        "        if not finished_beams:\n",
        "            finished_beams = beam\n",
        "\n",
        "        finished_beams.sort(key=lambda x: x[1])  # Sort in ascending order of score\n",
        "        ys, _, _, _, _ = finished_beams[0]  # Select the beam with the lowest score\n",
        "\n",
        "        return ys\n",
        "\n",
        "    def validate_and_extend_steps(self, current_state, states, steps, next_answer):\n",
        "        # Ensure any tensor operations are on the GPU\n",
        "        if len(steps) == 0 and current_state == \"LENGTH\":\n",
        "            length_value = self.sdr_idea_deserializer.get_numeric_value(next_answer[0, -6:].to(next_answer.device), 0)[0]\n",
        "\n",
        "            if length_value <= 0:\n",
        "                length_value = 1\n",
        "            else:\n",
        "                if length_value > 10:\n",
        "                    length_value = 10\n",
        "\n",
        "            metadata_type = self.sdr_idea_deserializer.get_metadata_type(\n",
        "                int(self.sdr_idea_deserializer.get_local_string_value(next_answer[0, -7].item()))\n",
        "            )\n",
        "            if metadata_type in [\"STRING_ARRAY\", \"STRING_VALUE\"]:\n",
        "                steps.extend(int(length_value) * self.get_steps(\"STRING_VALUE\"))\n",
        "            elif metadata_type in [\"NUM_ARRAY\", \"NUM_VALUE\"]:\n",
        "                steps.extend(int(length_value) * self.get_steps(\"NUM_VALUE\"))\n",
        "\n",
        "            current_state = \"VALUE\"\n",
        "\n",
        "        return current_state\n",
        "\n",
        "    def get_allowed_tokens(self, current_state, states, steps):\n",
        "        current_step = None\n",
        "\n",
        "        if len(steps) == 0:\n",
        "            current_state = states.pop(0)\n",
        "\n",
        "            if len(states) == 0:\n",
        "                states = self.get_states(True)\n",
        "\n",
        "            steps = self.get_steps(current_state)\n",
        "\n",
        "        if current_state is None:\n",
        "            current_state = states[0]\n",
        "\n",
        "        current_step = steps.pop(0)\n",
        "        allowed_tokens = self.get_step_index()[current_step]\n",
        "\n",
        "        return current_state, current_step, states, steps, allowed_tokens\n",
        "\n",
        "    def get_steps(self, state):\n",
        "        return self.steps_dict[state].copy()\n",
        "\n",
        "    def get_states(self, is_parent=False):\n",
        "        return self.parent_states.copy() if is_parent else self.states.copy()\n",
        "\n",
        "    def get_step_index(self):\n",
        "        return self.step_index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRlzSYhgPo5M"
      },
      "source": [
        "## Metric Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPODpydQOHpp"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from scipy.stats import entropy\n",
        "from sklearn.metrics import jaccard_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from pympler import asizeof\n",
        "import gc\n",
        "from memory_profiler import memory_usage\n",
        "\n",
        "def print_variable_size(variable, name):\n",
        "    size = asizeof.asizeof(variable)\n",
        "    print(f\"Tamanho da variável '{name}': {size / (1024 ** 2):.2f} MB\")\n",
        "\n",
        "def track_all_objects():\n",
        "    all_objects = gc.get_objects()\n",
        "    for obj in all_objects:\n",
        "        print(f\"Objeto: {type(obj)}, Tamanho: {asizeof.asizeof(obj)} bytes\")\n",
        "\n",
        "\n",
        "def test_with_deserializer(model, test_data_loader, device, temperature=1, beam_size=1, deserializer=None):\n",
        "    %reload_ext memory_profiler\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    desired_size = 374\n",
        "    model.eval()\n",
        "    loop = tqdm(test_data_loader)\n",
        "\n",
        "    fully_plan_correct = 0\n",
        "    correct_ideas_converted = 0\n",
        "    diverse_plan_count = 0\n",
        "    diverse_correct_plan_count = 0\n",
        "\n",
        "    diversity_scores = []\n",
        "    bleu_scores = []\n",
        "\n",
        "    batch_metrics = []\n",
        "\n",
        "    sdr_idea_array_predictor = SDRIdeaArrayPredictor(sdr_idea_deserializer=deserializer)\n",
        "\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch_idx, (input, label) in enumerate(loop):\n",
        "            input = input.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            def run_beam_search():\n",
        "                return sdr_idea_array_predictor.beam_search(\n",
        "                    model=model, src=input, start_symbol=1, end_symbol=2, max_len=desired_size,\n",
        "                    beam_size=beam_size,\n",
        "                    sdr_idea_deserializer=deserializer, device=device,\n",
        "                    temperature=temperature\n",
        "                )\n",
        "\n",
        "            result = run_beam_search()\n",
        "\n",
        "            if result.size(1) > desired_size:\n",
        "                result = result[:, :desired_size]\n",
        "            elif result.size(1) < desired_size:\n",
        "                zeros_needed = desired_size - result.size(1)\n",
        "                zeros_tensor = torch.zeros((result.size(0), zeros_needed), dtype=result.dtype).to(device)\n",
        "                result = torch.cat((result, zeros_tensor), dim=1)\n",
        "\n",
        "            result = result.long()\n",
        "\n",
        "            try:\n",
        "                goal_numpy = input.view(-1)\n",
        "                sdr_idea_array_goal = SDRIdeaArray(total_of_ideas=6, total_of_values=7, default_value=0)\n",
        "                sdr_idea_array_goal.sdr = goal_numpy\n",
        "\n",
        "                deserialized_goal = deserializer.deserialize(sdr_idea_array_goal)\n",
        "                start_token_id_tensor = torch.tensor([1]).to(device)\n",
        "                label_numpy = torch.cat([start_token_id_tensor, label.view(-1)], dim=0)\n",
        "                sdr_idea_array_label = SDRIdeaArray(total_of_ideas=6, total_of_values=7, default_value=0)\n",
        "                sdr_idea_array_label.sdr = label_numpy\n",
        "\n",
        "                deserialized_label = deserializer.deserialize(sdr_idea_array_label)\n",
        "                full_label = [deserialized_label] + deserialized_label.child_ideas\n",
        "\n",
        "                result_numpy = torch.cat([start_token_id_tensor, result.view(-1)], dim=0)\n",
        "\n",
        "                sdr_idea_array = SDRIdeaArray(total_of_ideas=6, total_of_values=7, default_value=0)\n",
        "                sdr_idea_array.sdr = result_numpy\n",
        "\n",
        "                deserialized_result = deserializer.deserialize(sdr_idea_array)\n",
        "\n",
        "                full_plan = [deserialized_result] + deserialized_result.child_ideas\n",
        "\n",
        "                verify_correct_idea = all(is_valid_idea(idea) for idea in full_plan)\n",
        "\n",
        "                is_valid = False\n",
        "\n",
        "                if verify_correct_idea:\n",
        "                    correct_ideas_converted += 1\n",
        "                    initial_node = next(filter(lambda x: x.name == 'initialNode', deserialized_goal.child_ideas), None)\n",
        "                    goal_action = next(filter(lambda x: x.name == 'goalAction', deserialized_goal.child_ideas), None)\n",
        "                    occupied_nodes = next(filter(lambda x: x.name == 'occupiedNodes', deserialized_goal.child_ideas), None)\n",
        "\n",
        "                    if is_valid_plan_v2(action=\"PICK\" if goal_action.value == 2 else 'PLACE',\n",
        "                                        initial_node=initial_node.value if initial_node is not None else None,\n",
        "                                        plan_steps=full_plan,\n",
        "                                        occupiedNodes=occupied_nodes.value if occupied_nodes is not None else []):\n",
        "                        fully_plan_correct += 1\n",
        "                        is_valid = True\n",
        "\n",
        "                # Verifica se o plano é diferente do label\n",
        "                if torch.sum(torch.sum(result, dim=1) - torch.sum(label, dim=1) != 0).item() > 0:\n",
        "                    diverse_plan_count += 1  # Contabiliza plano como diverso\n",
        "                    if is_valid:\n",
        "                        diverse_correct_plan_count += 1  # Contabiliza plano como diverso e correto\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Deserialization error in batch {batch_idx + 1}: {e}\")\n",
        "                print(result)\n",
        "\n",
        "            total_samples += label.size(0)\n",
        "\n",
        "            # BLEU score calculation\n",
        "            batch_bleu_scores = []\n",
        "            for i in range(label.size(0)):\n",
        "                reference_ids = label[i].cpu().numpy().tolist()\n",
        "                hypothesis_ids = result[i].cpu().numpy().tolist()\n",
        "\n",
        "                bleu_score = sentence_bleu([reference_ids], hypothesis_ids)\n",
        "                bleu_scores.append(bleu_score)\n",
        "                batch_bleu_scores.append(bleu_score)\n",
        "\n",
        "            # Jaccard diversity calculation\n",
        "            batch_diversity_scores = []\n",
        "            for i in range(label.size(0)):\n",
        "                jaccard_dist = jaccard_score(label[i].cpu().numpy(), result[i].cpu().numpy(), average='macro')\n",
        "                diversity_scores.append(jaccard_dist)\n",
        "                batch_diversity_scores.append(jaccard_dist)\n",
        "\n",
        "            batch_correct_ideas_converted = correct_ideas_converted / total_samples if total_samples > 0 else 0\n",
        "            batch_plan_correct = fully_plan_correct / total_samples if total_samples > 0 else 0\n",
        "            batch_diverse_correct_plan = diverse_correct_plan_count / diverse_plan_count if diverse_plan_count > 0 else 0\n",
        "\n",
        "            batch_metrics.append({\n",
        "                \"batch_idx\": batch_idx + 1,\n",
        "                \"average_bleu_score\": float(np.mean(bleu_scores)),\n",
        "                \"average_jaccard_score\": float(np.mean(diversity_scores)),\n",
        "                \"percentage_correct_ideas_converted\": float(batch_correct_ideas_converted),\n",
        "                \"percentage_fully_plan_correct\": float(batch_plan_correct),\n",
        "                \"percentage_diversity_correct_plan\": float(batch_diverse_correct_plan),\n",
        "            })\n",
        "\n",
        "            loop.set_description(\n",
        "                f\"Batch {batch_idx + 1}/{len(test_data_loader)} - \"\n",
        "                f\"BLEU: {np.mean(bleu_scores) * 100:.2f}%, \"\n",
        "                f\"Jaccard: {np.mean(diversity_scores):.4f}, \"\n",
        "                f\"Ideas Correct: {batch_correct_ideas_converted * 100:.2f}%, \"\n",
        "                f\"Plan Correct: {batch_plan_correct * 100:.2f}%, \"\n",
        "                f\"Diverse Correct Plan: {batch_diverse_correct_plan * 100:.2f}%, \"\n",
        "                f\"Total of Diverse Plans: {diverse_plan_count}\"\n",
        "            )\n",
        "\n",
        "    percentage_diverse_correct_plan = (diverse_correct_plan_count / diverse_plan_count) * 100 if diverse_plan_count > 0 else 0\n",
        "    final_metrics = {\n",
        "        \"percentage_correct_ideas_converted\": float(correct_ideas_converted / total_samples * 100),\n",
        "        \"percentage_fully_plan_correct\": float(fully_plan_correct / total_samples * 100),\n",
        "        \"percentage_diversity_correct_plan\": float(percentage_diverse_correct_plan),\n",
        "        \"average_bleu_score\": float(np.mean(bleu_scores)),\n",
        "        \"average_jaccard_diversity_score\": float(np.mean(diversity_scores))\n",
        "    }\n",
        "\n",
        "    output_dir = \"/content/drive/MyDrive/data/models/generators\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    with open(os.path.join(output_dir, f\"batch_metrics_temperature_{str(temperature)}_beam_size_{str(beam_size)}_generator.json\"), \"w\") as batch_file:\n",
        "        json.dump(batch_metrics, batch_file, indent=4)\n",
        "\n",
        "    with open(os.path.join(output_dir, f\"final_metrics_temperature_{str(temperature)}_beam_size_{str(beam_size)}_generator.json\"), \"w\") as final_file:\n",
        "        json.dump(final_metrics, final_file, indent=4)\n",
        "\n",
        "    print(f\"Final Metrics:\")\n",
        "    print(f\"Percentage of Fully Converted Sequences: {fully_plan_correct / total_samples * 100:.2f}%\")\n",
        "    print(f\"Percentage of Correctly Converted Ideas: {correct_ideas_converted / total_samples * 100:.2f}%\")\n",
        "    print(f\"Percentage of Correct Plans: {fully_plan_correct / total_samples * 100:.2f}%\")\n",
        "    print(f\"Percentage of Diverse Correct Plans: {percentage_diverse_correct_plan:.2f}%\")\n",
        "    print(f\"Average BLEU Score: {np.mean(bleu_scores) * 100:.2f}%\")\n",
        "    print(f\"Average Jaccard Score (Diversity): {np.mean(diversity_scores):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution"
      ],
      "metadata": {
        "id": "PQE3X_kOnFft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCVBoS149hJn"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, temperature=0.25, beam_size=1, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RCKxOMkmeG9"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=1,  temperature=0.5, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS9bMLF5-cJe"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=1,  temperature=0.625, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyKkRdK4hrKG"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=1,  temperature=0.75, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ho99QZJcwgRy"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=1,  temperature=1, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKQW5dnr_SeA"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=2,  temperature=0.25, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VkQGu1trZEy"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=2,  temperature=0.5, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KnfoDCvBwq5r"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=2,  temperature=0.625, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YibQxCgp4LMq"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=2,  temperature=0.75, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ41ScRAENbo"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=2,  temperature=1, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v85VdXarlXk3"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=3,  temperature=0.25, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vMLNziNUlZdW"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=3,  temperature=0.5, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ejzxRXolwwAk"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=3,  temperature=0.625, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "V9XMv6GEooIm"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=3,  temperature=0.75, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAzdLoHmosMA"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=3,  temperature=1, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-eFhik3rRsMO"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=4,  temperature=0.25, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TVDIGrZrQXxm"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=4,  temperature=0.5, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aWIIXInxQYwO"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=4,  temperature=0.625, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fV_MQxFBQZWK"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=4,  temperature=0.75, deserializer=sdr_idea_deserializer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0atsPEfuQZop"
      },
      "outputs": [],
      "source": [
        "test_with_deserializer(gen, test_data_loader, device, beam_size=4,  temperature=1, deserializer=sdr_idea_deserializer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}